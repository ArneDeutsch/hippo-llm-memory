# Default evaluation configuration.
tasks: []

# Basic run parameters with reasonable defaults.
suite: null
preset: baselines/core
n: 5
seed: 0
outdir: null
dry_run: false

# Report macro averaged scores in addition to micro scores.
macro_scoring: true

# Number of replay cycles to run between evaluations in ``eval_bench``.
post_replay_cycles: 0

# Replay evaluation options for ``eval_model`` (kept for backwards compat).
replay:
  cycles: 0

# Hydra stays in-place so our manual ``outdir`` handling works.
hydra:
  run:
    dir: .
  output_subdir: null

# Placeholder for ablation flags exposed via ``+ablate=...`` on the CLI.
ablate: {}
