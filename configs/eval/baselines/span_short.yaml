# Span-style baseline: chat template ON + short exact answers. (Option B)
memory: null
replay:
  cycles: 0
retrieval:
  enabled: false
long_context:
  enabled: false
gating_enabled: false
suites: [episodic, semantic, spatial, episodic_multi, episodic_cross, episodic_capacity]

# Generation/encoding tweaks (consumed by scripts/eval_model.py)
use_chat_template: true
system_prompt: "Answer with the exact shortest span from the prompt. No explanations."
max_new_tokens: 8
