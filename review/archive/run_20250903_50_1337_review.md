# Evaluation & Memory-Pipeline Review — run_20250903_50_1337

_Generated: 2025-09-03 14:36 UTC_

## TL;DR — What this run tells us
- **Memory wasn’t actually exercised**: all `gating.*.attempts == 0` across memory runs; preflight is correct to complain.
- **Stores are mostly empty**: `sgc_rss` (semantic KG) and `smpd` (spatial map) wrote **0 items**. `hei_nw` (episodic) has 53 items but marked `source: replay` and uses trivial/constant keys.
- **Baselines saturate some benches**: `semantic` and `episodic_cross` reach 0.94–1.00 EM without memory, so they can’t reveal uplift.
- **No credible uplift yet**: small deltas (e.g., `hei_nw` +0.04 EM on `episodic`) occur despite zero gating attempts -> noise, not memory benefit.
- **Pipeline is half-configured**: Step 4.3 produced artifacts, but since _teach_ → _test_ transitions and routing are disabled/dry-run, the evaluation cannot answer whether the algorithms work.

## What was run & where to look
- Run folder: `runs/run_20250903_50_1337/`
- Tasks present (n=50, seed=1337): episodic, episodic_multi, episodic_cross, episodic_capacity, semantic, spatial — under three baseline presets (`core`, `span_short`, `longctx`) and memory presets for `hei_nw`, `sgc_rss`, `smpd`.
- Baselines completeness marker: `baselines/baselines_ok.flag` exists.

### Baseline performance (EM/F1)
| preset     | suite             |   EM |       F1 |
|:-----------|:------------------|-----:|---------:|
| core       | episodic          | 0.08 | 0.206    |
| longctx    | episodic          | 0.28 | 0.413333 |
| span_short | episodic          | 0.1  | 0.246303 |
| core       | episodic_capacity | 0    | 0.32     |
| longctx    | episodic_capacity | 0    | 0.3      |
| span_short | episodic_capacity | 0    | 0.303333 |
| core       | episodic_cross    | 1    | 1        |
| longctx    | episodic_cross    | 0.98 | 0.993333 |
| span_short | episodic_cross    | 1    | 1        |
| core       | episodic_multi    | 0.48 | 0.48     |
| longctx    | episodic_multi    | 0.64 | 0.64     |
| span_short | episodic_multi    | 0.52 | 0.526667 |
| core       | semantic          | 0.94 | 0.94     |
| longctx    | semantic          | 1    | 1        |
| span_short | semantic          | 0.98 | 0.98     |
| core       | spatial           | 0    | 0        |
| longctx    | spatial           | 0    | 0        |
| span_short | spatial           | 0    | 0        |

### Memory performance vs baseline
| algo    | suite             |   EM |   ΔEM vs core |       F1 |   ΔF1 vs core |   store_size | store_source   | phase   |
|:--------|:------------------|-----:|--------------:|---------:|--------------:|-------------:|:---------------|:--------|
| hei_nw  | episodic          | 0.12 |          0.04 | 0.236833 |    0.0308333  |           53 | replay         | test    |
| hei_nw  | episodic_capacity | 0    |          0    | 0.28     |   -0.04       |           53 | replay         | test    |
| hei_nw  | episodic_cross    | 0.98 |         -0.02 | 0.993333 |   -0.00666667 |           53 | replay         | test    |
| hei_nw  | episodic_multi    | 0.46 |         -0.02 | 0.46     |   -0.02       |           53 | replay         | test    |
| sgc_rss | semantic          | 0.96 |          0.02 | 0.96     |    0.02       |            0 | teach          | test    |
| smpd    | spatial           | 0    |          0    | 0        |    0          |            0 | teach          | test    |

### Router/gating activity (sum over 50 samples)
| algo    | suite             |   episodic.attempts |   relational.attempts |   spatial.attempts |
|:--------|:------------------|--------------------:|----------------------:|-------------------:|
| hei_nw  | episodic          |                   0 |                     0 |                  0 |
| hei_nw  | episodic_capacity |                   0 |                     0 |                  0 |
| hei_nw  | episodic_cross    |                   0 |                     0 |                  0 |
| hei_nw  | episodic_multi    |                   0 |                     0 |                  0 |
| sgc_rss | semantic          |                   0 |                     0 |                  0 |
| smpd    | spatial           |                   0 |                     0 |                  0 |

## Memory store inspection
### `hei_nw` (episodic)
- File: `stores/hei_nw/hei_run_20250903_50_1337/episodic.jsonl` (53 lines).
- **Key vectors**: 4 unique; variance=0.008722. Many rows share constant vectors like all-zeros or all 0.353553 → likely placeholder embeddings.
- **Provenance examples**: ['the Cafe', 'the Library', 'the Mall', 'the Park'] (tokens_span is `[0,0]` in all inspected rows).
- **Interpretation**: store entries look synthetic (`state_sketch` mirrors a location string), with no surface text span or dense embedding — not useful for retrieval.

### `sgc_rss` (semantic KG) & `smpd` (spatial)
- Files:
  - `stores/sgc_rss/sgc_run_20250903_50_1337/kg.jsonl` → **0 bytes**
  - `stores/smpd/smpd_run_20250903_50_1337/spatial.jsonl` → **0 bytes**
- **Interpretation**: writers didn’t run or were gated off; there is no graph/map to query in test.

## Input audit samples
- 30 audit files exist (one per task/preset). These are good for spot-checking prompts/answers, but they weren’t used to populate memory (no teach writes observed).
## Findings
- **Router is idle**: every `*.attempts` counter is 0. Preflight guard that halts on `gate.attempts == 0 in dry-run` is correctly revealing that routing/memory calls are disabled or short-circuited.
- **Teach phase missing/ineffective**: `store.source` shows `replay` for `hei_nw` and `teach` for the others **with size 0**. There’s no evidence of a successful _teach → test_ handoff that writes items and then reads them.
- **Bench saturation**: `semantic` and `episodic_cross` reach ≥0.98 EM in baselines; they’re useful as smoke tests but won’t show uplift. `episodic_capacity` has EM=0 for all configs (F1 ~0.28–0.32), so evaluation should rely on F1/steps rather than EM there.
- **Long context helps multi-episodic**: `longctx` improves `episodic_multi` to 0.64 EM over `core` 0.48. Any memory algorithm must at least match/beat this baseline, or it’s not competitive.
- **Episodic store quality is poor**: constant/degenerate embedding keys and zero token spans suggest a placeholder writer; without informative keys and spans, retrieval can’t work.
- **Compute/latency is captured** but routing is not; without counts like `inserted`, `accepted`, `routed_to_episodic`>0, we can’t attribute any metric changes to memory.
## Recommendations to make the evaluation meaningful
- **Unblock routing**: turn off `dry_run` and ensure the router calls memory. Add a hard assert in preflight: for every memory suite, `sum(gating.*.attempts) > 0` and either `inserted > 0` (teach) or `routed_to_* > 0` (test).
- **Run an explicit TEACH pass**: Populate stores from `_teach` split before testing. After teach, assert `store.size >= n * min_expected_writes_per_sample` (e.g., ≥50 for episodic).
- **Fix store writers**:
-   - `hei_nw`: produce non-degenerate embeddings; write real `tokens_span` into source transcripts; include `trace_id`/`sample_id` so we can align writes with evaluations.
-   - `sgc_rss`: write `nodes` (entities) and `edges` with typed relations. Add diagnostics counters like `nodes_added`, `edges_added`, `coref_merges`.
-   - `smpd`: write normalized coordinates/landmarks; include `room→object` relations; persist occupancy grid or landmark graph.
- **Add retrieval diagnostics** (per sample): `router_path`, `topk_keys`, `distance`, `memory_hit` bool, and `justification` string. Aggregate hit-rate and contribution to EM/F1.
- **Change primary KPIs per suite**:
-   - `episodic`: EM/F1 + **hit-rate** and **latency delta** when memory is used.
-   - `episodic_multi`: EM/F1 vs `longctx` baseline; also per-step suboptimality.
-   - `episodic_capacity`: prioritize **F1**, **steps_to_goal**, **suboptimality_ratio** over EM.
-   - `semantic`: move to **harder split**; today it saturates (0.98–1.00 EM).
-   - `spatial`: define a first success criterion (any EM>0 or steps_to_goal reduction); without writes, it’s guaranteed 0.
- **Tighten preflight**:
-   - Fail if `store.size == 0` after teach for any memory preset expected to write.
-   - Fail if `attempts == 0` in test for any memory preset.
-   - Warn if `EM` within ±0.02 of baseline while `attempts>0` (likely unused memory).
- **Use a single RUN_ID** (you already moved here): propagate unchanged everywhere to avoid path mismatches. Ensure store namespaces are `algo_run_<RUN_ID>_<n>_<seed>` consistently.
- **Keep saturated benches only as smoke tests**: label them "non-informative for uplift" in the report; don’t gate releases on them.
- **Document a minimal success bar**: e.g., `episodic` +0.10 EM over `core` and ≥ `longctx` EM; `spatial` ≥0.10 EM or ≥20% steps reduction.
## Concrete next steps (in order)
1. Enable teach writes for all memories; verify `store.size` > 0 and `inserted > 0`.
1. Disable dry-run; ensure router attempts > 0 in test; sample 5 items with `memory_hit=true`.
1. Fix `hei_nw` embeddings/tokens_span; re-run `episodic` and verify uplift vs `longctx`.
1. Harden `sgc_rss` KG writer; move `semantic` to harder split or adversarial distractors; target uplift vs `longctx`.
1. Implement `smpd` write/read path; add a trivial navigation memory to get EM>0 on `spatial`.
1. Upgrade preflight assertions per above; fail early when memory is inert.
1. Regenerate reports and compare deltas; keep saturated benches as smoke tests only.